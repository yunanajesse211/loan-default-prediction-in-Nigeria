# -*- coding: utf-8 -*-
"""loan_default.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_DWI4D78shOmunOiP0vHM7OCfTCKUAnO

## Library Importation and Data Importation
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Flatten,Dropout
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.svm import SVR
from sklearn.metrics import accuracy_score,confusion_matrix, classification_report, precision_score, recall_score,f1_score,roc_auc_score
import warnings
warnings.filterwarnings('ignore')

# from google.colab import files
# files.upload()

df1 = pd.read_csv("train3.csv")
df2= pd.read_csv("train2.xls")
df3 = pd.read_csv("train1.xls")

df4=pd.merge(df1,df2, how='inner',on='customerid')

df=pd.merge(df4,df3, how='inner',on='customerid')
df4

df.info()

# df=df.dropna()
# df

df.describe()

df=df.drop_duplicates()

df

df = df.drop(["referredby_x","referredby_y",'bank_branch_clients','level_of_education_clients'], axis = 1)

data=df
data

data.info()

df=df.dropna()
df

df.info()

list(df['bank_name_clients'].unique())

list(df['employment_status_clients'].unique())

df = df.drop(["customerid","systemloanid_x",'approveddate_x','approveddate_y','creationdate_y','creationdate_x','closeddate','firstduedate','firstrepaiddate','systemloanid_y'], axis = 1)
df

df.info()

s=list(df['birthdate'])
df=df.drop('birthdate', axis=1)

ages=[]
for w in s:
    w=w.split()
    w=w[0]
    w=int(w[:4])
    age=2020-w
    ages.append(age)
df['ages']=ages

df

df.info()





df.good_bad_flag.value_counts()

plt.figure(figsize=(15,7))
sns.countplot(x = "good_bad_flag", data = df)

plt.figure(figsize=(15,7))
sns.countplot(x='ages',data=df,hue='good_bad_flag')

plt.figure(figsize=(15,7))
sns.countplot(x='loanamount_x',data=df,hue='good_bad_flag')

plt.figure(figsize=(15,7))
sns.countplot(x='bank_name_clients',data=df,hue='good_bad_flag')
plt.xticks(rotation=90)

plt.figure(figsize=(15,7))
sns.countplot(x='bank_account_type',data=df,hue='good_bad_flag')

plt.figure(figsize=(15,7))
sns.countplot(x='employment_status_clients',data=df,hue='good_bad_flag')

df

obj_columns=['good_bad_flag','bank_account_type','bank_name_clients','employment_status_clients']
le=LabelEncoder()
for x in obj_columns:
    df[x]=le.fit_transform(df[x])
df.head()

plt.figure(figsize = (15, 10))
sns.heatmap(df.corr(), annot = True)



"""## Data Splitting 1"""

x = df.drop('good_bad_flag', axis=1)
y = df['good_bad_flag']

x

y

"""## Feature Selection"""

rf = RandomForestClassifier()
rf.fit(x,y)
feature_importances = rf.feature_importances_
importance_df = pd.DataFrame({'Feature': x.columns, 'Importance': feature_importances})
importance_df = importance_df.sort_values(by='Importance', ascending=False)
ifs=importance_df['Feature'][:10]
selected_columns = list(ifs)
print(selected_columns)

plt.figure(figsize=(13,7))
plt.bar(ifs, importance_df['Importance'][:10], color='black')
plt.xlabel('Features')
plt.ylabel('Importance')
plt.title('Feature Importances')
plt.xticks(rotation=90)
plt.show()

x = df[['longitude_gps', 'latitude_gps', 'ages', 'loannumber_y', 'bank_name_clients', 'totaldue_y', 'employment_status_clients', 'loanamount_y', 'termdays_y', 'totaldue_x']]

x

sc=StandardScaler()
x = sc.fit_transform(x)

from imblearn.over_sampling import SMOTE
smote = SMOTE()
x, y = smote.fit_resample(x, y)

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.8)

scm_model = SVC()
scm_model.fit(x_train, y_train)
scm_pred = scm_model.predict(x_test)
print(classification_report(scm_pred, y_test))
print('precision score:',precision_score(y_test,scm_pred))
print('Recall score:',recall_score(y_test,scm_pred))
print('F1 score:',f1_score(y_test,scm_pred))

plt.figure(figsize=(10,6))
fx=sns.heatmap(confusion_matrix(y_test, scm_pred),annot=True,fmt='.0f',cmap='GnBu')
fx.set_xlabel('PREDICTED VALUES')
fx.set_ylabel('ACTUAL VALUES')
plt.show()

lg_model = LogisticRegression()
lg_model.fit(x_train, y_train)
lg_pred = lg_model.predict(x_test)
print(classification_report(lg_pred, y_test))
print('precision score:',precision_score(y_test,lg_pred))
print('Recall score:',recall_score(y_test,lg_pred))
print('F1 score:',f1_score(y_test,lg_pred))

plt.figure(figsize=(10,6))
fx=sns.heatmap(confusion_matrix(y_test, lg_pred),annot=True,fmt='.0f',cmap='GnBu')
fx.set_xlabel('PREDICTED VALUES')
fx.set_ylabel('ACTUAL VALUES')
plt.show()

from sklearn.ensemble import RandomForestClassifier

rf_model = RandomForestClassifier()
rf_model.fit(x_train, y_train)
rf_pred = rf_model.predict(x_test)
print(classification_report(rf_pred, y_test))
print('precision score:',precision_score(y_test,rf_pred))
print('Recall score:',recall_score(y_test,rf_pred))
print('F1 score:',f1_score(y_test,rf_pred))

plt.figure(figsize=(10,6))
fx=sns.heatmap(confusion_matrix(y_test, rf_pred),annot=True,fmt='.0f',cmap='GnBu')
fx.set_xlabel('PREDICTED VALUES')
fx.set_ylabel('ACTUAL VALUES')
plt.show()

from sklearn.neural_network import MLPClassifier
mlp=MLPClassifier(hidden_layer_sizes=(128,64))
mlp.fit(x_train, y_train)
mlp_pred= mlp.predict(x_test)
print(classification_report(mlp_pred, y_test))
print('precision score:',precision_score(y_test,mlp_pred))
print('Recall score:',recall_score(y_test,mlp_pred))
print('F1 score:',f1_score(y_test,mlp_pred))

plt.figure(figsize=(10,6))
fx=sns.heatmap(confusion_matrix(y_test, mlp_pred),annot=True,fmt='.0f',cmap='GnBu')
fx.set_xlabel('PREDICTED VALUES')
fx.set_ylabel('ACTUAL VALUES')
plt.show()

model=Sequential()
model.add(Dense(124,activation='relu',input_shape=(10,)))
model.add(Dense(64,activation='relu'))
model.add(Flatten())
model.add(Dense(64,activation='relu'))
model.add(Flatten())
model.add(Dense(64,activation='relu'))
model.add(Dense(64,activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(1, activation='sigmoid'))
model.summary()

model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])
his=model.fit(x_train,y_train,epochs=100,batch_size=32,validation_data=(x_test, y_test))
ann_pred=model.predict(x_test)
ann_pred=(ann_pred>=0.5).astype(int)
ann_pred

plt.figure(figsize=(10,5))
plt.plot(his.history['loss'])
plt.plot(his.history['val_loss'])
plt.legend(['train','test'])
plt.title('Model loss')
plt.ylabel('loss')
plt.xlabel('Epochs')
plt.show()

plt.figure(figsize=(10,5))
plt.plot(his.history['accuracy'])
plt.plot(his.history['val_accuracy'])
plt.legend(['train','test'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epochs')
plt.show()

print(classification_report(ann_pred, y_test))
print('precision score:',precision_score(y_test,ann_pred))
print('Recall score:',recall_score(y_test,ann_pred))
print('F1 score:',f1_score(y_test,ann_pred))

plt.figure(figsize=(10,6))
fx=sns.heatmap(confusion_matrix(y_test, ann_pred),annot=True,fmt='.0f',cmap='GnBu')
fx.set_xlabel('PREDICTED VALUES')
fx.set_ylabel('ACTUAL VALUES')
plt.show()

from sklearn.ensemble import StackingClassifier

stacking_clf = StackingClassifier(estimators=[('rf', rf_model), ('nn', mlp)], final_estimator=mlp)
stacking_clf.fit(x_train, y_train)
stacking_pred = stacking_clf.predict(x_test)
print(classification_report(stacking_pred, y_test))
print('precision score:',precision_score(y_test,stacking_pred))
print('Recall score:',recall_score(y_test,stacking_pred))
print('F1 score:',f1_score(y_test,stacking_pred))

plt.figure(figsize=(10,6))
fx=sns.heatmap(confusion_matrix(y_test, stacking_pred),annot=True,fmt='.0f',cmap='GnBu')
fx.set_xlabel('PREDICTED VALUES')
fx.set_ylabel('ACTUAL VALUES')
plt.show()

from sklearn.model_selection import cross_val_score,StratifiedKFold

kFold=StratifiedKFold(n_splits=5)
cv_scores = cross_val_score(stacking_clf, x_train, y_train, cv=kFold, scoring='accuracy')
print(f"Cross-validation scores: {cv_scores}")
print(f"Mean accuracy: {cv_scores.mean()}")
stacking_clf.fit(x_train,y_train)
predictions = stacking_clf.predict(x_test)
print(classification_report(predictions,y_test))

print('precision score:',precision_score(y_test,stacking_pred))
print('Recall score:',recall_score(y_test,stacking_pred))
print('F1 score:',f1_score(y_test,stacking_pred))

plt.figure(figsize=(10,6))
fx=sns.heatmap(confusion_matrix(y_test, stacking_pred),annot=True,fmt='.0f',cmap='GnBu')
fx.set_xlabel('PREDICTED VALUES')
fx.set_ylabel('ACTUAL VALUES')
plt.show()

import pickle

with open('model.pkl','wb') as file:
    pickle.dump(stacking_clf,file)